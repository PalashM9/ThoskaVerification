{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yRRpVsZsrKMm"
      },
      "outputs": [],
      "source": [
        "!pip install -U git+https://github.com/faustomorales/keras-ocr.git\n",
        "!pip install -U opencv-python==4.5.1.48\n",
        "%tensorflow_version 2.x"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  from google.colab import drive\n",
        "  import os\n",
        "  drive.mount('/content/drive')\n",
        "  data_dir = 'drive/My Drive/colab/keras-ocr'\n",
        "  os.makedirs(data_dir, exist_ok=True)\n",
        "except ImportError:\n",
        "  data_dir = '.'"
      ],
      "metadata": {
        "id": "OjNxVX99rLXo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import datetime\n",
        "import string\n",
        "import glob\n",
        "import math\n",
        "import os\n",
        "\n",
        "import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import sklearn.model_selection\n",
        "\n",
        "import keras_ocr\n",
        "\n",
        "assert tf.test.is_gpu_available()\n"
      ],
      "metadata": {
        "id": "IPsoN1NNrOf5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "alphabet = string.digits\n",
        "fonts = keras_ocr.data_generation.get_fonts(\n",
        "    alphabet=alphabet,\n",
        "    cache_dir=data_dir\n",
        ")\n",
        "backgrounds = keras_ocr.data_generation.get_backgrounds(cache_dir=data_dir)"
      ],
      "metadata": {
        "id": "tIfpwnQxrQCV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "def my_numbers_generator(_alphabet):\n",
        "    while True:\n",
        "        _sentence = \"\".join([_alphabet[random.randint(0, len(_alphabet) - 1)] for i in range(random.randint(1, 40))]) # TODO\n",
        "        yield _sentence"
      ],
      "metadata": {
        "id": "OsSWRpCrrRgW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "alphabet = string.digits\n",
        "text_generator = my_numbers_generator(alphabet)\n",
        "\n",
        "def get_train_val_test_split(arr):\n",
        "    train, valtest = sklearn.model_selection.train_test_split(arr, train_size=0.8, random_state=42)\n",
        "    val, test = sklearn.model_selection.train_test_split(valtest, train_size=0.5, random_state=42)\n",
        "    return train, val, test\n",
        "\n",
        "background_splits = get_train_val_test_split(backgrounds)\n",
        "font_splits = get_train_val_test_split(fonts)\n",
        "\n",
        "image_generators = [\n",
        "    keras_ocr.data_generation.get_image_generator(\n",
        "        height=640,\n",
        "        width=640,\n",
        "        text_generator=text_generator,\n",
        "        font_groups={\n",
        "            alphabet: current_fonts\n",
        "        },\n",
        "        backgrounds=current_backgrounds,\n",
        "        font_size=(80, 100),        \n",
        "        # parametrs for text placement\n",
        "        margin=50,\n",
        "        # rotation around horizontal axis\n",
        "        rotationX=(-0.001, 0.001),\n",
        "        # rotation around vertical axis\n",
        "        rotationY=(-0.01, 0.01),\n",
        "        # rotation in the plane of image\n",
        "        rotationZ=(-10, 10) \n",
        "    )  for current_fonts, current_backgrounds in zip(\n",
        "        font_splits,\n",
        "        background_splits\n",
        "    )\n",
        "]\n",
        "\n",
        "# See what the first validation image looks like.\n",
        "image, lines = next(image_generators[1])\n",
        "text = keras_ocr.data_generation.convert_lines_to_paragraph(lines)\n",
        "plt.imshow(image)\n"
      ],
      "metadata": {
        "id": "u6s3xgqzrT8d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "detector = keras_ocr.detection.Detector()\n",
        "recognizer = keras_ocr.recognition.Recognizer(\n",
        "    alphabet=alphabet,\n",
        "    weights='kurapan'\n",
        ")\n",
        "recognizer.compile()\n",
        "\n",
        "#Module 8\n",
        "max_length = 41\n",
        "recognition_image_generators = [\n",
        "    keras_ocr.data_generation.convert_image_generator_to_recognizer_input(\n",
        "        image_generator=image_generator,\n",
        "        max_string_length=min(recognizer.training_model.input_shape[1][1], max_length),\n",
        "        target_width=recognizer.model.input_shape[2],\n",
        "        target_height=recognizer.model.input_shape[1],\n",
        "        margin=1\n",
        "    ) for image_generator in image_generators\n",
        "]\n",
        "\n",
        "# See what the first validation image for recognition training looks like.\n",
        "image, text = next(recognition_image_generators[1])\n",
        "plt.imshow(image)\n"
      ],
      "metadata": {
        "id": "F1Z4GaA9rVqt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "recognition_batch_size = 8\n",
        "recognizer_basepath = os.path.join(data_dir, f'recognizer_{datetime.datetime.now().isoformat()}')\n",
        "recognition_train_generator, recognition_val_generator, recogntion_test_generator = [\n",
        "    recognizer.get_batch_generator(\n",
        "      image_generator=image_generator,\n",
        "      batch_size=recognition_batch_size,\n",
        "      lowercase=True\n",
        "    ) for image_generator in recognition_image_generators\n",
        "]\n",
        "recognizer.training_model.fit_generator(\n",
        "    generator=recognition_train_generator,\n",
        "    epochs=1000,\n",
        "    steps_per_epoch=math.ceil(len(background_splits[0]) / recognition_batch_size),\n",
        "    callbacks=[\n",
        "      tf.keras.callbacks.EarlyStopping(restore_best_weights=True, patience=35),\n",
        "      tf.keras.callbacks.CSVLogger(f'{recognizer_basepath}.csv', append=True),\n",
        "      tf.keras.callbacks.ModelCheckpoint(filepath=f'{recognizer_basepath}.h5')\n",
        "    ],\n",
        "    validation_data=recognition_val_generator,\n",
        "    validation_steps=math.ceil(len(background_splits[1]) / recognition_batch_size),\n",
        "    workers=0\n",
        ")"
      ],
      "metadata": {
        "id": "talXXKw1rXOg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline = keras_ocr.pipeline.Pipeline(detector=detector, recognizer=recognizer)\n",
        "image, lines = next(image_generators[0])\n",
        "predictions = pipeline.recognize(images=[image])[0]\n",
        "drawn = keras_ocr.tools.drawBoxes(\n",
        "    image=image, boxes=predictions, boxes_format='predictions'\n",
        ")\n",
        "print(\n",
        "    'Actual:', '\\n'.join([' '.join([character for _, character in line]) for line in lines]),\n",
        "    'Predicted:', [text for text, box in predictions])\n",
        "plt.imshow(drawn)"
      ],
      "metadata": {
        "id": "5OZy-IPirXxF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}